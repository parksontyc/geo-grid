{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad814819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0541e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®€å–æ–¹æ ¼ç¶²æ ¼è³‡æ–™\n",
    "save_path_grid = r\"C:\\labs\\geo-grid\\data\\output_grids\\grids_100m\\Grid_æ–°åŒ—å¸‚_100m.parquet\"\n",
    "grid_loaded = gpd.read_parquet(save_path_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525a3c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®€å–åœ°åœ–è³‡æ–™\n",
    "save_path_map = r\"C:\\labs\\geo-grid\\data\\output_grids\\grids_100m\\gdf_tm2.parquet\"\n",
    "map_loaded = gpd.read_parquet(save_path_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b29ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®€å–é¤é£²æ¥­POIè³‡æ–™\n",
    "save_path_gdf = r\"C:\\labs\\geo-grid\\data\\output_poi\\catering_gdf.parquet\"\n",
    "catering_loaded = gpd.read_parquet(save_path_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cca6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "catering_anlyzed = catering_loaded.loc[catering_loaded['è¡Œæ”¿å€'] == 'æ–°èŠå€'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ue7fb06t4a",
   "metadata": {},
   "source": [
    "# é¤é£²æ¥­å•†æ¥­å€åˆ†ææµç¨‹\n",
    "ä¾æ“š README.md å¯¦ä½œå®Œæ•´çš„ç©ºé–“åˆ†ææµç¨‹ï¼š\n",
    "1. POI ç‰¹å¾µå·¥ç¨‹èˆ‡è¨ˆåˆ†\n",
    "2. ç¶²æ ¼é¤é£²ç«åŠ› (KDE)\n",
    "3. å•†æ¥­å€è­˜åˆ¥ (Local Moran's I / LISA)\n",
    "4. ç”Ÿæˆå•†æ¥­å€ (HH grids â†’ Clusters)\n",
    "5. å•†åœˆå®šç¾©èˆ‡åˆ†ç´š\n",
    "6. æ•æ„Ÿåº¦åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5x4dr4trfzk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from esda.moran import Moran_Local\n",
    "from libpysal.weights import DistanceBand\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ch2twzoxeur",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹ä¸‰é‡å€é¤é£²æ¥­POIè³‡æ–™\n",
    "print(f\"ä¸‰é‡å€é¤é£²æ¥­POIæ•¸é‡: {len(catering_anlyzed)}\")\n",
    "catering_anlyzed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ocglqwsnf4",
   "metadata": {},
   "source": [
    "## 1. POI ç‰¹å¾µå·¥ç¨‹èˆ‡è¨ˆåˆ†\n",
    "\n",
    "### 1.1 æ¥­æ…‹åˆ†é¡èˆ‡æ¬Šé‡è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z5qgx0kdh1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šç¾©æ¥­æ…‹åˆ†é¡èˆ‡æ¬Šé‡\n",
    "# åŸºæ–¼READMEå»ºè­°ï¼šç›®çš„å‹ > è£œçµ¦å‹ï¼Œæ˜“çŒæ°´é¡ï¼ˆæ‰‹æ–é£²ã€æ”¤è²©ï¼‰éœ€è¨­cap\n",
    "\n",
    "def classify_purpose_type(row):\n",
    "    \"\"\"åˆ†é¡ç‚ºç›®çš„å‹/è£œçµ¦å‹\"\"\"\n",
    "    name = row['åç¨±']\n",
    "    business_type = row['å‹æ…‹']\n",
    "    \n",
    "    # ç›®çš„å‹ï¼šé¤å»³é¡ï¼ˆæ­£é¤ç‚ºä¸»ï¼‰\n",
    "    if any(keyword in name for keyword in ['é¤é¤¨', 'é¤å»³', 'ç«é‹', 'ç‡’çƒ¤', 'æ—¥æœ¬æ–™ç†', 'ç¾©å¼', 'æ³•å¼', 'æ³°å¼', 'éŸ“å¼']):\n",
    "        return 'ç›®çš„å‹'\n",
    "    # è£œçµ¦å‹ï¼šè¼•é£Ÿã€é£²æ–™ã€ä¾¿åˆ©å•†åº—ç­‰\n",
    "    elif any(keyword in name for keyword in ['é£²æ–™åº—', 'å’–å•¡', 'èŒ¶', 'é»å¿ƒ', 'éºµåŒ…', 'ç”œé»', 'å°åƒ']):\n",
    "        return 'è£œçµ¦å‹'\n",
    "    else:\n",
    "        return 'è£œçµ¦å‹'  # é è¨­ç‚ºè£œçµ¦å‹\n",
    "\n",
    "# å¥—ç”¨åˆ†é¡\n",
    "catering_anlyzed['purpose_type'] = catering_anlyzed.apply(classify_purpose_type, axis=1)\n",
    "\n",
    "# æª¢è¦–åˆ†é¡çµæœ\n",
    "print(catering_anlyzed['purpose_type'].value_counts())\n",
    "print(f\"\\næ¥­æ…‹(å‹æ…‹)åˆ†å¸ƒ:\")\n",
    "print(catering_anlyzed['å‹æ…‹'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d7wb4gx",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šç¾©æ¬Šé‡èˆ‡capå€¼\n",
    "weights_and_caps = {\n",
    "    'ç›®çš„å‹': {'weight': 1.0, 'cap': None},      # ä¸è¨­ä¸Šé™\n",
    "    'è£œçµ¦å‹': {'weight': 0.6, 'cap': 10},        # è£œçµ¦å‹æ¬Šé‡è¼ƒä½ï¼Œè¨­capé˜²æ­¢çŒæ°´\n",
    "}\n",
    "\n",
    "# å°‡æ¬Šé‡å’ŒcapåŠ å…¥DataFrame\n",
    "catering_anlyzed['weight'] = catering_anlyzed['purpose_type'].map(lambda x: weights_and_caps[x]['weight'])\n",
    "catering_anlyzed['cap'] = catering_anlyzed['purpose_type'].map(lambda x: weights_and_caps[x]['cap'])\n",
    "\n",
    "print(\"\\næ¬Šé‡èˆ‡capè¨­å®š:\")\n",
    "print(catering_anlyzed[['purpose_type', 'weight', 'cap']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "catering_anlyzed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2k5r2yax",
   "metadata": {},
   "source": [
    "### 1.2 ç©ºé–“å°ä½ï¼šPOI â†’ Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64988f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿®æ­£ï¼šPOI çš„åº§æ¨™å¯¦éš›ä¸Šæ˜¯ç¶“ç·¯åº¦ï¼Œéœ€è¦é‡æ–°è¨­å®š CRS ä¸¦è½‰æ›\n",
    "print(\"ä¿®æ­£ POI åº§æ¨™ç³»çµ±...\")\n",
    "\n",
    "# æª¢æŸ¥ POI åº§æ¨™ç¯„åœä¾†åˆ¤æ–·æ˜¯å¦ç‚ºç¶“ç·¯åº¦\n",
    "poi_x_range = catering_anlyzed.geometry.x.min(), catering_anlyzed.geometry.x.max()\n",
    "print(f\"POI X ç¯„åœ: {poi_x_range}\")\n",
    "\n",
    "# å¦‚æœ X åº§æ¨™åœ¨ 120-122 ä¹‹é–“ï¼Œè¡¨ç¤ºæ˜¯ç¶“ç·¯åº¦æ ¼å¼\n",
    "if 120 < poi_x_range[0] < 122:\n",
    "    print(\"åµæ¸¬åˆ° POI ä½¿ç”¨ç¶“ç·¯åº¦åº§æ¨™ï¼Œé‡æ–°è¨­å®š CRS...\")\n",
    "    \n",
    "    # å…ˆè¨­å®šç‚º WGS84 ç¶“ç·¯åº¦ (EPSG:4326)\n",
    "    catering_anlyzed_fixed = catering_anlyzed.copy()\n",
    "    catering_anlyzed_fixed.crs = \"EPSG:4326\"\n",
    "    \n",
    "    # è½‰æ›ç‚º TWD97 TM2 (EPSG:3826)\n",
    "    catering_anlyzed_fixed = catering_anlyzed_fixed.to_crs(\"EPSG:3826\")\n",
    "    \n",
    "    print(f\"è½‰æ›å¾Œçš„ POI ç¯„åœ: {catering_anlyzed_fixed.total_bounds}\")\n",
    "    print(f\"å‰3ç­†åº§æ¨™:\")\n",
    "    for idx, row in catering_anlyzed_fixed.head(3).iterrows():\n",
    "        print(f\"     {row.geometry}\")\n",
    "    \n",
    "    # ä½¿ç”¨ä¿®æ­£å¾Œçš„è³‡æ–™\n",
    "    catering_anlyzed = catering_anlyzed_fixed\n",
    "else:\n",
    "    print(\"POI åº§æ¨™å·²æ˜¯æŠ•å½±åº§æ¨™ï¼Œç„¡éœ€è½‰æ›\")\n",
    "\n",
    "# é‡æ–°åŸ·è¡Œç©ºé–“ join\n",
    "print(\"\\né‡æ–°åŸ·è¡Œ POI èˆ‡ç¶²æ ¼ç©ºé–“å°ä½...\")\n",
    "poi_with_grid = gpd.sjoin(catering_anlyzed, grid_sanzhong, how='inner', predicate='within')\n",
    "print(f\"æˆåŠŸå°ä½çš„POIæ•¸é‡: {len(poi_with_grid)}\")\n",
    "\n",
    "if len(poi_with_grid) > 0:\n",
    "    print(f\"\\nå°ä½æˆåŠŸï¼å‰5ç­†çµæœ:\")\n",
    "    print(poi_with_grid[['çµ±ä¸€ç·¨è™Ÿ', 'ç‡Ÿæ¥­äººåç¨±', 'å‹æ…‹', 'grid_id', 'TOWNNAME']].head())\n",
    "else:\n",
    "    print(\"\\nè­¦å‘Šï¼šå°ä½çµæœä»ç‚º0ï¼Œéœ€è¦é€²ä¸€æ­¥æª¢æŸ¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ywva9cc2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ­¥é©Ÿ1: ä½¿ç”¨ç©ºé–“ join å°‡ grid èˆ‡è¡Œæ”¿å€è³‡æ–™åˆä½µ\n",
    "print(\"æ­£åœ¨åˆä½µç¶²æ ¼èˆ‡è¡Œæ”¿å€è³‡æ–™...\")\n",
    "grid_with_town = gpd.sjoin(\n",
    "    grid_loaded, \n",
    "    map_loaded[['COUNTYNAME', 'TOWNNAME', 'geometry']], \n",
    "    how='left', \n",
    "    predicate='within'\n",
    ")\n",
    "\n",
    "print(f\"åˆä½µå®Œæˆï¼Œç¸½ç¶²æ ¼æ•¸: {len(grid_with_town)}\")\n",
    "print(f\"\\nè¡Œæ”¿å€åˆ†å¸ƒ (å‰10å):\")\n",
    "print(grid_with_town['TOWNNAME'].value_counts().head(10))\n",
    "\n",
    "# æ­¥é©Ÿ2: ç¯©é¸æ–°åŒ—å¸‚ä¸‰é‡å€çš„ç¶²æ ¼\n",
    "grid_sanzhong = grid_with_town[\n",
    "    (grid_with_town['COUNTYNAME'] == 'æ–°åŒ—å¸‚') & \n",
    "    (grid_with_town['TOWNNAME'] == 'æ–°èŠå€')\n",
    "].copy()\n",
    "\n",
    "# æ¸…ç†ç©ºé–“ join ç”¢ç”Ÿçš„é¡å¤–æ¬„ä½\n",
    "if 'index_right' in grid_sanzhong.columns:\n",
    "    grid_sanzhong = grid_sanzhong.drop(columns=['index_right'])\n",
    "\n",
    "print(f\"\\nä¸‰é‡å€ç¶²æ ¼æ•¸é‡: {len(grid_sanzhong)}\")\n",
    "print(f\"ç¶²æ ¼æ¬„ä½: {grid_sanzhong.columns.tolist()}\")\n",
    "\n",
    "\n",
    "# æ­¥é©Ÿ3: ç¢ºä¿å…©è€…ä½¿ç”¨ç›¸åŒçš„CRS\n",
    "if catering_anlyzed.crs != grid_sanzhong.crs:\n",
    "    catering_anlyzed = catering_anlyzed.to_crs(grid_sanzhong.crs)\n",
    "    \n",
    "print(f\"\\nCRS ç¢ºèª:\")\n",
    "print(f\"  POI CRS: {catering_anlyzed.crs}\")\n",
    "print(f\"  Grid CRS: {grid_sanzhong.crs}\")\n",
    "\n",
    "# æ­¥é©Ÿ4: ç©ºé–“join - POI within Grid\n",
    "print(\"\\nåŸ·è¡Œ POI èˆ‡ç¶²æ ¼ç©ºé–“å°ä½...\")\n",
    "poi_with_grid = gpd.sjoin(catering_anlyzed, grid_sanzhong, how='inner', predicate='within')\n",
    "print(f\"æˆåŠŸå°ä½çš„POIæ•¸é‡: {len(poi_with_grid)}\")\n",
    "\n",
    "# é¡¯ç¤ºçµæœ\n",
    "print(f\"\\nå°ä½çµæœé è¦½:\")\n",
    "poi_with_grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨ºæ–·ï¼šæª¢æŸ¥ç‚ºä»€éº¼å°ä½çµæœç‚º 0\n",
    "print(\"=== è¨ºæ–·è³‡è¨Š ===\")\n",
    "print(f\"\\n1. POI è³‡æ–™:\")\n",
    "print(f\"   æ•¸é‡: {len(catering_anlyzed)}\")\n",
    "print(f\"   CRS: {catering_anlyzed.crs}\")\n",
    "print(f\"   ç¯„åœ: {catering_anlyzed.total_bounds}\")\n",
    "print(f\"   å‰3ç­†åº§æ¨™:\")\n",
    "for idx, row in catering_anlyzed.head(3).iterrows():\n",
    "    print(f\"     {row.geometry}\")\n",
    "\n",
    "print(f\"\\n2. ç¶²æ ¼è³‡æ–™:\")\n",
    "print(f\"   æ•¸é‡: {len(grid_sanzhong)}\")\n",
    "print(f\"   CRS: {grid_sanzhong.crs}\")\n",
    "print(f\"   ç¯„åœ: {grid_sanzhong.total_bounds}\")\n",
    "print(f\"   å‰3ç­†ç¶²æ ¼:\")\n",
    "for idx, row in grid_sanzhong.head(3).iterrows():\n",
    "    print(f\"     {row.geometry.bounds}\")\n",
    "\n",
    "# æª¢æŸ¥åº§æ¨™ç³»çµ±æ˜¯å¦åŒ¹é…\n",
    "print(f\"\\n3. CRS æ¯”è¼ƒ:\")\n",
    "print(f\"   POI: {catering_anlyzed.crs.to_string()}\")\n",
    "print(f\"   Grid: {grid_sanzhong.crs.to_string()}\")\n",
    "print(f\"   æ˜¯å¦ç›¸åŒ: {catering_anlyzed.crs == grid_sanzhong.crs}\")\n",
    "\n",
    "# æª¢æŸ¥ç©ºé–“ç¯„åœæ˜¯å¦é‡ç–Š\n",
    "poi_bounds = catering_anlyzed.total_bounds\n",
    "grid_bounds = grid_sanzhong.total_bounds\n",
    "print(f\"\\n4. ç©ºé–“ç¯„åœæ¯”è¼ƒ:\")\n",
    "print(f\"   POI:  [{poi_bounds[0]:.2f}, {poi_bounds[1]:.2f}] to [{poi_bounds[2]:.2f}, {poi_bounds[3]:.2f}]\")\n",
    "print(f\"   Grid: [{grid_bounds[0]:.2f}, {grid_bounds[1]:.2f}] to [{grid_bounds[2]:.2f}, {grid_bounds[3]:.2f}]\")\n",
    "\n",
    "# æª¢æŸ¥æ˜¯å¦æœ‰äº¤é›†\n",
    "has_overlap = not (poi_bounds[2] < grid_bounds[0] or poi_bounds[0] > grid_bounds[2] or \n",
    "                   poi_bounds[3] < grid_bounds[1] or poi_bounds[1] > grid_bounds[3])\n",
    "print(f\"   ç¯„åœæ˜¯å¦é‡ç–Š: {has_overlap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e00d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713073cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3klpowxkl2y",
   "metadata": {},
   "source": [
    "### 1.3 è¨ˆç®—æ¯æ ¼è¨ˆåˆ† (raw_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mwubt4kage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŒ‰ç…§ grid_id å’Œ purpose_type åˆ†çµ„çµ±è¨ˆ\n",
    "count_by_grid_type = poi_with_grid.groupby(['grid_id', 'purpose_type']).size().reset_index(name='count')\n",
    "\n",
    "# åˆä½µæ¬Šé‡å’Œcapè³‡è¨Š\n",
    "count_by_grid_type = count_by_grid_type.merge(\n",
    "    poi_with_grid[['purpose_type', 'weight', 'cap']].drop_duplicates(),\n",
    "    on='purpose_type',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# è¨ˆç®— s_{k,i} = w_k * log(1 + min(count_{k,i}, cap_k))\n",
    "def calculate_score(row):\n",
    "    count = row['count']\n",
    "    weight = row['weight']\n",
    "    cap = row['cap']\n",
    "    \n",
    "    # å¦‚æœæœ‰capï¼Œå‰‡ä½¿ç”¨min(count, cap)ï¼›å¦å‰‡ç›´æ¥ä½¿ç”¨count\n",
    "    effective_count = min(count, cap) if cap is not None else count\n",
    "    score = weight * np.log(1 + effective_count)\n",
    "    return score\n",
    "\n",
    "count_by_grid_type['score'] = count_by_grid_type.apply(calculate_score, axis=1)\n",
    "\n",
    "print(\"æ¯æ ¼æ¯é¡è¨ˆåˆ†çµæœ:\")\n",
    "print(count_by_grid_type.head(10))\n",
    "\n",
    "# è¨ˆç®—æ¯æ ¼ç¸½åˆ† raw_i = Î£_k s_{k,i}\n",
    "grid_raw = count_by_grid_type.groupby('grid_id')['score'].sum().reset_index(name='raw_i')\n",
    "print(f\"\\nè¨ˆç®—å®Œæˆï¼Œå…± {len(grid_raw)} å€‹ç¶²æ ¼æœ‰é¤é£²POI\")\n",
    "print(f\"raw_i çµ±è¨ˆ:\\n{grid_raw['raw_i'].describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fquxbg7v0on",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°‡raw_iåˆä½µå›ç¶²æ ¼è³‡æ–™\n",
    "grid_with_raw = grid_sanzhong.merge(grid_raw, on='grid_id', how='left')\n",
    "# æ²’æœ‰POIçš„ç¶²æ ¼ï¼Œraw_iè¨­ç‚º0\n",
    "grid_with_raw['raw_i'] = grid_with_raw['raw_i'].fillna(0)\n",
    "\n",
    "print(f\"ç¶²æ ¼ç¸½æ•¸: {len(grid_with_raw)}\")\n",
    "print(f\"æœ‰é¤é£²POIçš„ç¶²æ ¼æ•¸: {(grid_with_raw['raw_i'] > 0).sum()}\")\n",
    "grid_with_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1o2nz9updls",
   "metadata": {},
   "source": [
    "## 2. ç¶²æ ¼é¤é£²ç«åŠ› (KDE - Kernel Density Estimation)\n",
    "\n",
    "æ¡ç”¨æ–¹æ¡ˆAï¼šä½¿ç”¨ç¶²æ ¼ä¸­å¿ƒé»ä½œç‚ºKDEè©•ä¼°é»ï¼Œæ¬Šé‡ç‚ºraw_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rqnegj1abkf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨ˆç®—ç¶²æ ¼ä¸­å¿ƒé»\n",
    "grid_with_raw['centroid'] = grid_with_raw.geometry.centroid\n",
    "grid_with_raw['centroid_x'] = grid_with_raw['centroid'].x\n",
    "grid_with_raw['centroid_y'] = grid_with_raw['centroid'].y\n",
    "\n",
    "print(\"ç¶²æ ¼ä¸­å¿ƒé»è¨ˆç®—å®Œæˆ\")\n",
    "print(grid_with_raw[['grid_id', 'centroid_x', 'centroid_y', 'raw_i']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5hh011uf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kde_density(grid_gdf, bandwidth=600, alpha=1):\n",
    "    \"\"\"\n",
    "    è¨ˆç®—KDEå¯†åº¦\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        grid_gdf: åŒ…å«centroid_x, centroid_y, raw_içš„GeoDataFrame\n",
    "        bandwidth: KDEé »å¯¬ (å–®ä½: å…¬å°º)\n",
    "        alpha: è·é›¢è¡°æ¸›åƒæ•¸ (æœªä½¿ç”¨æ–¼æ¨™æº–KDEï¼Œä½†ä¿ç•™ä¾›åƒè€ƒ)\n",
    "    \n",
    "    è¿”å›:\n",
    "        æ·»åŠ äº†D_iæ¬„ä½çš„DataFrame\n",
    "    \"\"\"\n",
    "    # åªä½¿ç”¨æœ‰POIçš„ç¶²æ ¼ä½œç‚ºæºé»\n",
    "    source_grids = grid_gdf[grid_gdf['raw_i'] > 0].copy()\n",
    "    \n",
    "    if len(source_grids) == 0:\n",
    "        grid_gdf['D_i'] = 0\n",
    "        return grid_gdf\n",
    "    \n",
    "    # æº–å‚™æºé»åº§æ¨™å’Œæ¬Šé‡\n",
    "    source_coords = source_grids[['centroid_x', 'centroid_y']].values\n",
    "    weights = source_grids['raw_i'].values\n",
    "    \n",
    "    # æº–å‚™è©•ä¼°é»ï¼ˆæ‰€æœ‰ç¶²æ ¼çš„ä¸­å¿ƒé»ï¼‰\n",
    "    eval_coords = grid_gdf[['centroid_x', 'centroid_y']].values\n",
    "    \n",
    "    # ä½¿ç”¨é«˜æ–¯æ ¸è¨ˆç®—KDE\n",
    "    # bandwidth éœ€è¦è½‰æ›ç‚ºé©åˆçš„å–®ä½\n",
    "    kde = KernelDensity(bandwidth=bandwidth, kernel='gaussian')\n",
    "    \n",
    "    # ç‚ºæ¯å€‹æºé»é‡è¤‡è¨ˆç®—ï¼Œæ¬Šé‡åŠ æˆ\n",
    "    densities = np.zeros(len(eval_coords))\n",
    "    \n",
    "    for i, (coord, weight) in enumerate(zip(source_coords, weights)):\n",
    "        # å°æ¯å€‹æºé»fit KDE\n",
    "        kde.fit(coord.reshape(1, -1))\n",
    "        # è¨ˆç®—åˆ°æ‰€æœ‰è©•ä¼°é»çš„å¯†åº¦\n",
    "        log_dens = kde.score_samples(eval_coords)\n",
    "        # åŠ æ¬Šç´¯åŠ \n",
    "        densities += weight * np.exp(log_dens)\n",
    "    \n",
    "    grid_gdf['D_i'] = densities\n",
    "    return grid_gdf\n",
    "\n",
    "# åŸ·è¡ŒKDEè¨ˆç®— (é è¨­é »å¯¬ 600m)\n",
    "print(\"é–‹å§‹è¨ˆç®—KDEå¯†åº¦...\")\n",
    "grid_with_kde = compute_kde_density(grid_with_raw.copy(), bandwidth=600)\n",
    "print(f\"KDEè¨ˆç®—å®Œæˆ\")\n",
    "print(f\"D_i çµ±è¨ˆ:\\n{grid_with_kde['D_i'].describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcg86qssy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨™æº–åŒ–ç‚º Score_i (0-100åˆ†)\n",
    "# ä½¿ç”¨åˆ†ä½æ•¸æ’å (rank_pct)\n",
    "grid_with_kde['rank_pct'] = grid_with_kde['D_i'].rank(pct=True)\n",
    "grid_with_kde['Score_i'] = grid_with_kde['rank_pct'] * 100\n",
    "\n",
    "print(f\"Score_i çµ±è¨ˆ:\\n{grid_with_kde['Score_i'].describe()}\")\n",
    "print(f\"\\nTop 10 é«˜åˆ†ç¶²æ ¼:\")\n",
    "print(grid_with_kde.nlargest(10, 'Score_i')[['grid_id', 'raw_i', 'D_i', 'Score_i']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37awgyv7sq4",
   "metadata": {},
   "source": [
    "## 3. å•†æ¥­å€è­˜åˆ¥ (Local Moran's I / LISA)\n",
    "\n",
    "ä½¿ç”¨è·é›¢è¡°æ¸›æ¬Šé‡çŸ©é™£è­˜åˆ¥HHï¼ˆHigh-Highï¼‰èšé›†å€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5twgi2z34vq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 æ¨™æº–åŒ– Score_i ç‚º z_i\n",
    "grid_with_kde['z_i'] = zscore(grid_with_kde['Score_i'])\n",
    "\n",
    "print(f\"z_i çµ±è¨ˆ:\\n{grid_with_kde['z_i'].describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "us6ggotsuc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 å»ºç«‹è·é›¢è¡°æ¸›æ¬Šé‡çŸ©é™£ï¼ˆä½¿ç”¨å„ªåŒ–åƒæ•¸ï¼‰\n",
    "def create_distance_decay_weights(grid_gdf, threshold=600, alpha=2):\n",
    "    \"\"\"\n",
    "    å»ºç«‹è·é›¢è¡°æ¸›æ¬Šé‡çŸ©é™£\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        grid_gdf: åŒ…å«centroidçš„GeoDataFrame\n",
    "        threshold: è·é›¢é–¾å€¼ d0 (å–®ä½: å…¬å°º) - æ”¹ç‚º 600m ä»¥ç¸®å°ç¯„åœ\n",
    "        alpha: è¡°æ¸›æŒ‡æ•¸ (w_ij = 1 / d_ij^alpha) - æ”¹ç‚º 2 ä»¥åŠ å¼·è¡°æ¸›\n",
    "    \n",
    "    è¿”å›:\n",
    "        libpysal.weights.W ç‰©ä»¶\n",
    "    \"\"\"\n",
    "    coords = np.array(list(zip(grid_gdf['centroid_x'], grid_gdf['centroid_y'])))\n",
    "    \n",
    "    # ä½¿ç”¨DistanceBandå»ºç«‹åŸºç¤æ¬Šé‡\n",
    "    w = DistanceBand(coords, threshold=threshold, binary=False)\n",
    "    \n",
    "    # æ‡‰ç”¨è·é›¢è¡°æ¸›\n",
    "    for i in w.neighbors:\n",
    "        for j_idx, j in enumerate(w.neighbors[i]):\n",
    "            # è¨ˆç®—è·é›¢\n",
    "            dist = np.linalg.norm(coords[i] - coords[j])\n",
    "            if dist > 0:  # é¿å…é™¤ä»¥0\n",
    "                # è·é›¢è¡°æ¸›æ¬Šé‡\n",
    "                w.weights[i][j_idx] = 1.0 / (dist ** alpha)\n",
    "            else:\n",
    "                w.weights[i][j_idx] = 0\n",
    "    \n",
    "    # Row-standardize\n",
    "    w.transform = 'r'\n",
    "    \n",
    "    return w\n",
    "\n",
    "print(\"å»ºç«‹æ¬Šé‡çŸ©é™£ï¼ˆå„ªåŒ–åƒæ•¸ï¼šthreshold=600m, alpha=2ï¼‰...\")\n",
    "w = create_distance_decay_weights(grid_with_kde, threshold=600, alpha=2)\n",
    "print(f\"æ¬Šé‡çŸ©é™£å»ºç«‹å®Œæˆ\")\n",
    "print(f\"å¹³å‡é„°å±…æ•¸: {w.mean_neighbors:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3i40f8qxo4p",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 è¨ˆç®— Local Moran's I\n",
    "print(\"è¨ˆç®— Local Moran's I...\")\n",
    "lisa = Moran_Local(grid_with_kde['z_i'].values, w, permutations=999)\n",
    "\n",
    "# æå–çµæœ\n",
    "grid_with_kde['I_i'] = lisa.Is  # Local Moran's I çµ±è¨ˆé‡\n",
    "grid_with_kde['p_value'] = lisa.p_sim  # p-value (æ¨¡æ“¬)\n",
    "\n",
    "# è¨ˆç®—ç©ºé–“æ»¯å¾Œå€¼ï¼šlag_z_i = Î£ w_ij * z_j\n",
    "# ä½¿ç”¨æ¬Šé‡çŸ©é™£æ‰‹å‹•è¨ˆç®—\n",
    "z_values = grid_with_kde['z_i'].values\n",
    "lag_z = np.zeros(len(z_values))\n",
    "for i in range(len(z_values)):\n",
    "    if i in w.neighbors:\n",
    "        neighbors = w.neighbors[i]\n",
    "        weights = w.weights[i]\n",
    "        lag_z[i] = sum(weights[j] * z_values[neighbors[j]] for j in range(len(neighbors)))\n",
    "\n",
    "grid_with_kde['lag_z_i'] = lag_z\n",
    "\n",
    "# å››è±¡é™åˆ†é¡\n",
    "quadrant_map = {1: 'HH', 2: 'LH', 3: 'LL', 4: 'HL', 0: 'Non-significant'}\n",
    "grid_with_kde['quadrant'] = [quadrant_map.get(q, 'Non-significant') for q in lisa.q]\n",
    "\n",
    "print(f\"LISAè¨ˆç®—å®Œæˆ\")\n",
    "print(f\"\\nå››è±¡é™åˆ†å¸ƒ:\")\n",
    "print(grid_with_kde['quadrant'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460vyaw5k8l",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 å¤šé‡æ¯”è¼ƒæ ¡æ­£ (BH-FDR)\n",
    "reject, q_values, _, _ = multipletests(grid_with_kde['p_value'], method='fdr_bh')\n",
    "grid_with_kde['q_value'] = q_values\n",
    "\n",
    "print(f\"FDRæ ¡æ­£å®Œæˆ\")\n",
    "print(f\"åŸå§‹ p < 0.05 çš„æ•¸é‡: {(grid_with_kde['p_value'] < 0.05).sum()}\")\n",
    "print(f\"FDR q < 0.05 çš„æ•¸é‡: {(grid_with_kde['q_value'] < 0.05).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abjv10eh1uk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 HHæ ¼å­ç¯©é¸ï¼ˆå¹³è¡¡çš„æ¢ä»¶ï¼‰\n",
    "# å››æ¢ä»¶ï¼š\n",
    "# 1. è‡ªèº«é«˜ (z_i > threshold)\n",
    "# 2. å‘¨é‚Šé«˜ (lag_z_i > threshold)  \n",
    "# 3. æ­£è‡ªç›¸é—œ (quadrant == 'HH')\n",
    "# 4. è¶Šè¿‘æ¬Šé‡è¶Šé«˜ (å·²åœ¨æ¬Šé‡çŸ©é™£ä¸­å¯¦ç¾: w_ij = 1/d^2)\n",
    "\n",
    "# ä½¿ç”¨å¹³è¡¡çš„æ¢ä»¶ï¼šæ—¢èƒ½è­˜åˆ¥å¤šå€‹å€åŸŸï¼Œåˆä¸æœƒå¤ªå¤§\n",
    "grid_with_kde['HH_flag'] = (\n",
    "    (grid_with_kde['quadrant'] == 'HH') &      # æ¢ä»¶3: æ­£è‡ªç›¸é—œ\n",
    "    (grid_with_kde['z_i'] > 0.75) &            # æ¢ä»¶1: è‡ªèº«é«˜ï¼ˆæé«˜è‡³0.75å€‹æ¨™æº–å·®ï¼‰\n",
    "    (grid_with_kde['lag_z_i'] > 0.3) &         # æ¢ä»¶2: å‘¨é‚Šé«˜ï¼ˆæé«˜è‡³0.3ï¼‰\n",
    "    (grid_with_kde['q_value'] < 0.05)          # çµ±è¨ˆé¡¯è‘—æ€§\n",
    ")\n",
    "\n",
    "print(f\"=== æ–°ä¸€é†¬å››æ¢ä»¶ç¯©é¸ï¼ˆå¹³è¡¡ç‰ˆï¼‰===\")\n",
    "print(f\"1. è‡ªèº«é«˜ (z_i > 0.75): {(grid_with_kde['z_i'] > 0.75).sum()} æ ¼\")\n",
    "print(f\"2. å‘¨é‚Šé«˜ (lag_z_i > 0.3): {(grid_with_kde['lag_z_i'] > 0.3).sum()} æ ¼\")\n",
    "print(f\"3. æ­£è‡ªç›¸é—œ (HH): {(grid_with_kde['quadrant'] == 'HH').sum()} æ ¼\")\n",
    "print(f\"4. è¶Šè¿‘æ¬Šé‡è¶Šé«˜: å·²åœ¨æ¬Šé‡çŸ©é™£å¯¦ç¾ (w_ij = 1/d^2)\")\n",
    "print(f\"\\né€šéå››æ¢ä»¶çš„HHæ ¼å­æ•¸é‡: {grid_with_kde['HH_flag'].sum()}\")\n",
    "\n",
    "hh_grids = grid_with_kde[grid_with_kde['HH_flag']]\n",
    "if len(hh_grids) > 0:\n",
    "    print(f\"\\nHHæ ¼å­çµ±è¨ˆ:\")\n",
    "    print(f\"  å¹³å‡ Score_i: {hh_grids['Score_i'].mean():.2f}\")\n",
    "    print(f\"  å¹³å‡ z_i: {hh_grids['z_i'].mean():.2f}\")\n",
    "    print(f\"  å¹³å‡ raw_i: {hh_grids['raw_i'].mean():.2f}\")\n",
    "    print(f\"  Score_i ç¯„åœ: {hh_grids['Score_i'].min():.1f} - {hh_grids['Score_i'].max():.1f}\")\n",
    "    print(f\"  åˆ†ä½æ•¸:\")\n",
    "    print(f\"    Q25: {hh_grids['Score_i'].quantile(0.25):.1f}\")\n",
    "    print(f\"    Q50: {hh_grids['Score_i'].quantile(0.50):.1f}\")\n",
    "    print(f\"    Q75: {hh_grids['Score_i'].quantile(0.75):.1f}\")\n",
    "    \n",
    "    # é¡¯ç¤ºå¯èª¿æ•´çš„åƒæ•¸å»ºè­°\n",
    "    print(f\"\\nğŸ“Š åƒæ•¸èª¿æ•´å»ºè­°:\")\n",
    "    print(f\"  - è‹¥å•†æ¥­å€å¤ªå¤§ï¼šæé«˜ z_i é–€æª»ï¼ˆå¦‚ 0.75 â†’ 1.0ï¼‰\")\n",
    "    print(f\"  - è‹¥å•†æ¥­å€å¤ªå°/å¤ªå°‘ï¼šé™ä½ z_i é–€æª»ï¼ˆå¦‚ 0.75 â†’ 0.5ï¼‰\")\n",
    "    print(f\"  - ç•¶å‰è¨­å®šï¼šz_i > 0.75, lag_z_i > 0.3, q < 0.05\")\n",
    "else:\n",
    "    print(\"\\nè­¦å‘Šï¼šæ²’æœ‰ç¬¦åˆå››æ¢ä»¶çš„HHæ ¼å­\")\n",
    "    print(\"å»ºè­°é™ä½é–€æª»\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wjwn3x1xl4",
   "metadata": {},
   "source": [
    "## 4. ç”Ÿæˆå•†æ¥­å€ (HH grids â†’ Clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7g16y9idj0y",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 ä½¿ç”¨é€£é€šæ€§åˆ†æè­˜åˆ¥ç¨ç«‹çš„clusters\n",
    "hh_grids = grid_with_kde[grid_with_kde['HH_flag']].copy()\n",
    "\n",
    "if len(hh_grids) > 0:\n",
    "    from scipy.sparse import csr_matrix\n",
    "    from scipy.sparse.csgraph import connected_components\n",
    "    \n",
    "    # å»ºç«‹é„°æ¥çŸ©é™£ï¼ˆåŸºæ–¼ç¶²æ ¼ç›¸é„°é—œä¿‚ï¼‰\n",
    "    n = len(hh_grids)\n",
    "    hh_grids_reset = hh_grids.reset_index(drop=True)\n",
    "    \n",
    "    # å»ºç«‹ç©ºé–“ç´¢å¼•åŠ é€Ÿ\n",
    "    from shapely.strtree import STRtree\n",
    "    tree = STRtree(hh_grids_reset.geometry)\n",
    "    \n",
    "    # æ‰¾å‡ºç›¸é„°çš„ç¶²æ ¼å°ï¼ˆä½¿ç”¨ touches æˆ–éå¸¸è¿‘çš„è·é›¢ï¼‰\n",
    "    adjacency_list = []\n",
    "    for i, geom in enumerate(hh_grids_reset.geometry):\n",
    "        # æ‰¾å‡ºèˆ‡ç•¶å‰ç¶²æ ¼ç›¸é„°æˆ–ç›¸æ¥çš„ç¶²æ ¼\n",
    "        nearby_indices = tree.query(geom.buffer(1))  # buffer 1m ä¾†ç¢ºä¿æ•æ‰åˆ°ç›¸é„°æ ¼å­\n",
    "        for j in nearby_indices:\n",
    "            if i < j:  # é¿å…é‡è¤‡\n",
    "                # æª¢æŸ¥æ˜¯å¦çœŸçš„ç›¸é„°ï¼ˆå…±äº«é‚Šç•Œæˆ–éå¸¸æ¥è¿‘ï¼‰\n",
    "                dist = hh_grids_reset.iloc[i].geometry.distance(hh_grids_reset.iloc[j].geometry)\n",
    "                if dist < 5:  # 5m ä»¥å…§è¦–ç‚ºç›¸é„°ï¼ˆ100mç¶²æ ¼æ‡‰è©²æ˜¯0æˆ–141.4mï¼‰\n",
    "                    adjacency_list.append((i, j))\n",
    "    \n",
    "    # å»ºç«‹ç¨€ç–é„°æ¥çŸ©é™£\n",
    "    if len(adjacency_list) > 0:\n",
    "        rows = [i for i, j in adjacency_list] + [j for i, j in adjacency_list]\n",
    "        cols = [j for i, j in adjacency_list] + [i for i, j in adjacency_list]\n",
    "        data = [1] * (len(adjacency_list) * 2)\n",
    "        adj_matrix = csr_matrix((data, (rows, cols)), shape=(n, n))\n",
    "        \n",
    "        # æ‰¾å‡ºé€£é€šåˆ†é‡\n",
    "        n_components, labels = connected_components(adj_matrix, directed=False)\n",
    "        \n",
    "        print(f\"ç™¼ç¾ {n_components} å€‹ç¨ç«‹çš„é€£é€šå€åŸŸ\")\n",
    "        \n",
    "        # å°‡ cluster label åŠ å…¥ hh_grids\n",
    "        hh_grids_reset['component'] = labels\n",
    "        \n",
    "        # ç‚ºæ¯å€‹é€£é€šåˆ†é‡å»ºç«‹ cluster polygon\n",
    "        clusters_list = []\n",
    "        for comp_id in range(n_components):\n",
    "            comp_grids = hh_grids_reset[hh_grids_reset['component'] == comp_id]\n",
    "            if len(comp_grids) > 0:\n",
    "                # åˆä½µè©²é€£é€šåˆ†é‡çš„æ‰€æœ‰æ ¼å­\n",
    "                from shapely.ops import unary_union\n",
    "                merged = unary_union(comp_grids.geometry)\n",
    "                clusters_list.append({\n",
    "                    'geometry': merged,\n",
    "                    'cluster_id': comp_id + 1,\n",
    "                    'n_grids_in_cluster': len(comp_grids)\n",
    "                })\n",
    "                print(f\"  Cluster {comp_id + 1}: {len(comp_grids)} æ ¼\")\n",
    "        \n",
    "        clusters = gpd.GeoDataFrame(clusters_list, crs=hh_grids.crs)\n",
    "    else:\n",
    "        # æ²’æœ‰ç›¸é„°é—œä¿‚ï¼Œæ¯å€‹æ ¼å­æ˜¯ç¨ç«‹çš„cluster\n",
    "        print(f\"æ²’æœ‰ç™¼ç¾ç›¸é„°çš„HHæ ¼å­ï¼Œæ¯å€‹æ ¼å­è¦–ç‚ºç¨ç«‹cluster\")\n",
    "        clusters_list = []\n",
    "        for idx, row in hh_grids_reset.iterrows():\n",
    "            clusters_list.append({\n",
    "                'geometry': row.geometry,\n",
    "                'cluster_id': idx + 1,\n",
    "                'n_grids_in_cluster': 1\n",
    "            })\n",
    "        clusters = gpd.GeoDataFrame(clusters_list, crs=hh_grids.crs)\n",
    "    \n",
    "    print(f\"\\nç¸½å…±ç”Ÿæˆ {len(clusters)} å€‹ clusters\")\n",
    "    \n",
    "else:\n",
    "    clusters = gpd.GeoDataFrame(columns=['geometry', 'cluster_id', 'n_grids_in_cluster'], crs=grid_with_kde.crs)\n",
    "    print(\"æ²’æœ‰HHæ ¼å­ï¼Œç„¡æ³•ç”Ÿæˆclusters\")\n",
    "\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fly3ygspr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 è¨ˆç®—clusterå±¬æ€§ï¼ˆä¿®æ­£ï¼šç¢ºä¿æ¯å€‹clusterç¨ç«‹è™•ç†ï¼‰\n",
    "if len(clusters) > 0:\n",
    "    print(f\"é–‹å§‹è¨ˆç®— {len(clusters)} å€‹ clusters çš„å±¬æ€§...\")\n",
    "    \n",
    "    # ç‚ºæ¯å€‹clusterè¨ˆç®—å±¬æ€§\n",
    "    cluster_stats_list = []\n",
    "    \n",
    "    for cluster_id in clusters['cluster_id']:\n",
    "        # ç²å–è©²clusterçš„å¹¾ä½•\n",
    "        cluster_geom = clusters[clusters['cluster_id'] == cluster_id].iloc[0].geometry\n",
    "        \n",
    "        # æ‰¾å‡ºè©²clusterå…§çš„HHæ ¼å­\n",
    "        hh_in_cluster = hh_grids[hh_grids.geometry.within(cluster_geom)]\n",
    "        \n",
    "        if len(hh_in_cluster) > 0:\n",
    "            cluster_stats_list.append({\n",
    "                'cluster_id': cluster_id,\n",
    "                'N_grids': len(hh_in_cluster),\n",
    "                'TotalPower': hh_in_cluster['Score_i'].sum(),\n",
    "                'Peak': hh_in_cluster['Score_i'].max(),\n",
    "            })\n",
    "        else:\n",
    "            print(f\"  è­¦å‘Š: Cluster {cluster_id} å…§æ²’æœ‰æ‰¾åˆ°HHæ ¼å­\")\n",
    "    \n",
    "    # è½‰ç‚ºDataFrame\n",
    "    cluster_stats = pd.DataFrame(cluster_stats_list)\n",
    "    \n",
    "    # è¨ˆç®—é¢ç© (kmÂ²)\n",
    "    clusters['Area_km2'] = clusters.geometry.area / 1_000_000\n",
    "    \n",
    "    # åˆä½µçµ±è¨ˆè³‡æ–™\n",
    "    clusters = clusters.merge(cluster_stats, on='cluster_id', how='left')\n",
    "    \n",
    "    print(f\"\\nCluster å±¬æ€§è¨ˆç®—å®Œæˆ:\")\n",
    "    for idx, row in clusters.iterrows():\n",
    "        print(f\"  Cluster {row['cluster_id']}: {row['N_grids']:.0f}æ ¼, \"\n",
    "              f\"TotalPower={row['TotalPower']:.1f}, \"\n",
    "              f\"Peak={row['Peak']:.1f}, \"\n",
    "              f\"é¢ç©={row['Area_km2']:.3f}kmÂ²\")\n",
    "else:\n",
    "    print(\"æ²’æœ‰clusterså¯çµ±è¨ˆ\")\n",
    "\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644nsho5mbq",
   "metadata": {},
   "source": [
    "## 5. å•†åœˆå®šç¾©èˆ‡åˆ†ç´š (Clusters â†’ Circles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0xcy77w7wy6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 åˆ†ç´šè¦å‰‡ï¼ˆæ¯å€‹clusterç¨ç«‹åˆ†ç´šï¼‰\n",
    "if len(clusters) > 0:\n",
    "    # è¨ˆç®—P90é–¾å€¼\n",
    "    p90_totalpower = clusters['TotalPower'].quantile(0.9)\n",
    "    mean_totalpower = clusters['TotalPower'].mean()\n",
    "    \n",
    "    print(f\"åˆ†ç´šé–€æª»:\")\n",
    "    print(f\"  TotalPower P90: {p90_totalpower:.1f}\")\n",
    "    print(f\"  TotalPower Mean: {mean_totalpower:.1f}\")\n",
    "    \n",
    "    def classify_tier(row):\n",
    "        \"\"\"ä¾æ“šN_gridså’ŒTotalPoweråˆ†ç´š\"\"\"\n",
    "        if pd.isna(row['N_grids']) or pd.isna(row['TotalPower']):\n",
    "            return 'Non-Circle'\n",
    "        if row['N_grids'] >= 10 and row['TotalPower'] >= p90_totalpower:\n",
    "            return 'Tier 1'\n",
    "        elif row['N_grids'] >= 4 and row['TotalPower'] >= mean_totalpower:\n",
    "            return 'Tier 2'\n",
    "        else:\n",
    "            return 'Non-Circle'\n",
    "    \n",
    "    clusters['tier'] = clusters.apply(classify_tier, axis=1)\n",
    "    \n",
    "    # ç¯©é¸å‡ºcircles (æ’é™¤Non-Circle)\n",
    "    circles = clusters[clusters['tier'] != 'Non-Circle'].copy()\n",
    "    \n",
    "    print(f\"\\nå•†åœˆåˆ†ç´šå®Œæˆ:\")\n",
    "    print(f\"  ç¸½ Clusters: {len(clusters)}\")\n",
    "    print(f\"  Tier 1: {len(clusters[clusters['tier'] == 'Tier 1'])}\")\n",
    "    print(f\"  Tier 2: {len(clusters[clusters['tier'] == 'Tier 2'])}\")\n",
    "    print(f\"  Non-Circle: {len(clusters[clusters['tier'] == 'Non-Circle'])}\")\n",
    "    print(f\"  ç¸½å•†åœˆæ•¸ (Circles): {len(circles)}\")\n",
    "    \n",
    "    if len(circles) > 0:\n",
    "        print(f\"\\nå•†åœˆè©³ç´°è³‡è¨Š:\")\n",
    "        for idx, row in circles.iterrows():\n",
    "            print(f\"  {row['tier']} - Cluster {row['cluster_id']}: \"\n",
    "                  f\"{row['N_grids']:.0f}æ ¼, \"\n",
    "                  f\"TotalPower={row['TotalPower']:.1f}, \"\n",
    "                  f\"é¢ç©={row['Area_km2']:.3f}kmÂ²\")\n",
    "else:\n",
    "    circles = gpd.GeoDataFrame(columns=['cluster_id', 'tier', 'geometry', 'N_grids', 'TotalPower', 'Peak', 'Area_km2'], \n",
    "                                crs=grid_with_kde.crs)\n",
    "    print(\"æ²’æœ‰clustersï¼Œç„¡æ³•åˆ†ç´š\")\n",
    "\n",
    "circles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0aba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨ºæ–·ï¼šæª¢æŸ¥clustersæ˜¯å¦æ­£ç¢ºåˆ†é›¢\n",
    "print(f\"\\n=== Clusters è¨ºæ–·è³‡è¨Š ===\")\n",
    "print(f\"ç¸½ Clusters æ•¸: {len(clusters)}\")\n",
    "if len(clusters) > 0:\n",
    "    print(f\"\\nå„ Cluster çš„å¹¾ä½•é¡å‹å’Œé‚Šç•Œ:\")\n",
    "    for idx, row in clusters.iterrows():\n",
    "        bounds = row.geometry.bounds\n",
    "        print(f\"  Cluster {row['cluster_id']}: \"\n",
    "              f\"é¡å‹={row.geometry.geom_type}, \"\n",
    "              f\"é‚Šç•Œ=[{bounds[0]:.0f}, {bounds[1]:.0f}, {bounds[2]:.0f}, {bounds[3]:.0f}]\")\n",
    "    \n",
    "    # æª¢æŸ¥æ˜¯å¦æœ‰ç©ºé–“é‡ç–Š\n",
    "    if len(clusters) > 1:\n",
    "        print(f\"\\næª¢æŸ¥ Clusters æ˜¯å¦é‡ç–Š:\")\n",
    "        for i in range(len(clusters)):\n",
    "            for j in range(i+1, len(clusters)):\n",
    "                geom_i = clusters.iloc[i].geometry\n",
    "                geom_j = clusters.iloc[j].geometry\n",
    "                if geom_i.intersects(geom_j):\n",
    "                    print(f\"  è­¦å‘Š: Cluster {i+1} å’Œ Cluster {j+1} æœ‰é‡ç–Š!\")\n",
    "                else:\n",
    "                    distance = geom_i.distance(geom_j)\n",
    "                    print(f\"  Cluster {i+1} å’Œ Cluster {j+1} è·é›¢: {distance:.1f}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e73cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨ºæ–·ï¼šæª¢æŸ¥ä¸åŒæ¢ä»¶ä¸‹çš„HHæ ¼å­åˆ†å¸ƒ\n",
    "print(\"=== HH æ ¼å­ç¯©é¸è¨ºæ–· ===\\n\")\n",
    "\n",
    "# æª¢æŸ¥å„æ¢ä»¶çš„å½±éŸ¿\n",
    "print(f\"1. LISA HH è±¡é™: {(grid_with_kde['quadrant'] == 'HH').sum()} æ ¼\")\n",
    "print(f\"2. z_i > 0: {(grid_with_kde['z_i'] > 0).sum()} æ ¼\")\n",
    "print(f\"3. z_i > 0.5: {(grid_with_kde['z_i'] > 0.5).sum()} æ ¼\")\n",
    "print(f\"4. z_i > 1.0: {(grid_with_kde['z_i'] > 1.0).sum()} æ ¼\")\n",
    "print(f\"5. lag_z_i > 0: {(grid_with_kde['lag_z_i'] > 0).sum()} æ ¼\")\n",
    "print(f\"6. lag_z_i > 0.5: {(grid_with_kde['lag_z_i'] > 0.5).sum()} æ ¼\")\n",
    "print(f\"7. q_value < 0.05: {(grid_with_kde['q_value'] < 0.05).sum()} æ ¼\")\n",
    "print(f\"8. q_value < 0.01: {(grid_with_kde['q_value'] < 0.01).sum()} æ ¼\")\n",
    "\n",
    "# çµ„åˆæ¢ä»¶\n",
    "cond_loose = (\n",
    "    (grid_with_kde['quadrant'] == 'HH') &\n",
    "    (grid_with_kde['z_i'] > 0) &\n",
    "    (grid_with_kde['lag_z_i'] > 0) &\n",
    "    (grid_with_kde['q_value'] < 0.05)\n",
    ")\n",
    "print(f\"\\nå¯¬é¬†æ¢ä»¶ (z>0, q<0.05): {cond_loose.sum()} æ ¼\")\n",
    "\n",
    "cond_current = (\n",
    "    (grid_with_kde['quadrant'] == 'HH') &\n",
    "    (grid_with_kde['z_i'] > 1.0) &\n",
    "    (grid_with_kde['lag_z_i'] > 0.5) &\n",
    "    (grid_with_kde['q_value'] < 0.01)\n",
    ")\n",
    "print(f\"ç•¶å‰æ¢ä»¶ (z>1.0, lag_z>0.5, q<0.01): {cond_current.sum()} æ ¼\")\n",
    "\n",
    "# æŸ¥çœ‹ HH æ ¼å­çš„ç©ºé–“åˆ†å¸ƒ\n",
    "hh_loose = grid_with_kde[cond_loose]\n",
    "if len(hh_loose) > 0:\n",
    "    print(f\"\\nå¯¬é¬†æ¢ä»¶ä¸‹ HH æ ¼å­çš„ç©ºé–“ç¯„åœ:\")\n",
    "    bounds = hh_loose.total_bounds\n",
    "    print(f\"  X: {bounds[0]:.0f} - {bounds[2]:.0f}\")\n",
    "    print(f\"  Y: {bounds[1]:.0f} - {bounds[3]:.0f}\")\n",
    "    print(f\"  è·¨åº¦: X={bounds[2]-bounds[0]:.0f}m, Y={bounds[3]-bounds[1]:.0f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r4wywsin4xb",
   "metadata": {},
   "source": [
    "## 6. è¦–è¦ºåŒ–çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y3no3b7bjvn",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import contextily as cx\n",
    "    use_basemap = True\n",
    "except ImportError:\n",
    "    print(\"è­¦å‘Š: contextily æœªå®‰è£ï¼Œå°‡ä¸é¡¯ç¤ºè¡—é“åœ–åº•åœ–\")\n",
    "    print(\"è«‹åŸ·è¡Œ: pip install contextily\")\n",
    "    use_basemap = False\n",
    "\n",
    "# å»ºç«‹è¦–è¦ºåŒ–\n",
    "fig, axes = plt.subplots(2, 2, figsize=(24, 20))\n",
    "\n",
    "# 1. Score_i åˆ†å¸ƒï¼ˆå¸¶è¡—é“åœ–ï¼‰- å…¨éƒ¨ç¶²æ ¼æ¼¸å±¤\n",
    "ax1 = axes[0, 0]\n",
    "grid_with_kde.plot(column='Score_i', cmap='YlOrRd', legend=True, ax=ax1, \n",
    "                    edgecolor='none', alpha=0.6, vmin=0, vmax=100,\n",
    "                    legend_kwds={'label': 'é¤é£²ç«åŠ› Score_i', 'shrink': 0.8})\n",
    "# ç¹ªè£½æ‰€æœ‰å•†åœˆé‚Šç•Œ\n",
    "if len(circles) > 0:\n",
    "    for idx, row in circles.iterrows():\n",
    "        color = 'darkred' if row['tier'] == 'Tier 1' else 'orange'\n",
    "        gpd.GeoSeries([row.geometry], crs=circles.crs).boundary.plot(\n",
    "            ax=ax1, color=color, linewidth=3, label=f\"{row['tier']} (Cluster {row['cluster_id']})\")\n",
    "# ç¹ªè£½POI\n",
    "catering_anlyzed.plot(ax=ax1, color='black', markersize=2, alpha=0.4)\n",
    "if use_basemap:\n",
    "    cx.add_basemap(ax1, crs=grid_with_kde.crs.to_string(), \n",
    "                   source=cx.providers.OpenStreetMap.Mapnik, alpha=0.5)\n",
    "ax1.set_title('Score_i åˆ†å¸ƒ + å•†åœˆé‚Šç•Œï¼ˆå«è¡—é“åœ–ï¼‰', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='upper right', fontsize=8)\n",
    "ax1.axis('off')\n",
    "\n",
    "# 2. LISA å››è±¡é™\n",
    "ax2 = axes[0, 1]\n",
    "quadrant_colors = {'HH': 'red', 'HL': 'pink', 'LH': 'lightblue', 'LL': 'blue', 'Non-significant': 'white'}\n",
    "for quad, color in quadrant_colors.items():\n",
    "    subset = grid_with_kde[grid_with_kde['quadrant'] == quad]\n",
    "    if len(subset) > 0:\n",
    "        subset.plot(ax=ax2, color=color, edgecolor='gray', linewidth=0.1, alpha=0.7, label=quad)\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.set_title('LISA å››è±¡é™åˆ†é¡', fontsize=14, fontweight='bold')\n",
    "ax2.axis('off')\n",
    "\n",
    "# 3. HHæ ¼å­ï¼ˆå¸¶è¡—é“åœ–ï¼‰\n",
    "ax3 = axes[1, 0]\n",
    "grid_with_kde.plot(ax=ax3, color='lightgray', edgecolor='white', linewidth=0.1, alpha=0.3)\n",
    "hh_grids = grid_with_kde[grid_with_kde['HH_flag']]\n",
    "if len(hh_grids) > 0:\n",
    "    hh_grids.plot(ax=ax3, color='red', edgecolor='darkred', linewidth=0.5, alpha=0.8)\n",
    "# ç¹ªè£½æ‰€æœ‰clusteré‚Šç•Œ\n",
    "if len(clusters) > 0:\n",
    "    clusters.boundary.plot(ax=ax3, color='blue', linewidth=2, label=f'{len(clusters)} Clusters')\n",
    "# ç¹ªè£½POI\n",
    "catering_anlyzed.plot(ax=ax3, color='black', markersize=1, alpha=0.3)\n",
    "if use_basemap:\n",
    "    cx.add_basemap(ax3, crs=grid_with_kde.crs.to_string(), \n",
    "                   source=cx.providers.OpenStreetMap.Mapnik, alpha=0.5)\n",
    "ax3.set_title(f'HH é«˜å€¼èšé›†å€ (n={len(hh_grids)}, {len(clusters)} clusters) + è¡—é“åœ–', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax3.legend(loc='upper right')\n",
    "ax3.axis('off')\n",
    "\n",
    "# 4. å•†åœˆåˆ†ç´šï¼ˆå¸¶è¡—é“åœ–ï¼‰\n",
    "ax4 = axes[1, 1]\n",
    "grid_with_kde.plot(ax=ax4, color='lightgray', edgecolor='white', linewidth=0.1, alpha=0.3)\n",
    "if len(circles) > 0:\n",
    "    tier_colors = {'Tier 1': 'darkred', 'Tier 2': 'orange'}\n",
    "    for tier, color in tier_colors.items():\n",
    "        subset = circles[circles['tier'] == tier]\n",
    "        if len(subset) > 0:\n",
    "            subset.plot(ax=ax4, facecolor=color, edgecolor='black', linewidth=2, \n",
    "                       alpha=0.5, label=f'{tier} ({len(subset)}å€‹)')\n",
    "# ç¹ªè£½POI\n",
    "catering_anlyzed.plot(ax=ax4, color='black', markersize=1, alpha=0.3)\n",
    "if use_basemap:\n",
    "    cx.add_basemap(ax4, crs=grid_with_kde.crs.to_string(), \n",
    "                   source=cx.providers.OpenStreetMap.Mapnik, alpha=0.5)\n",
    "ax4.legend(loc='upper right')\n",
    "ax4.set_title(f'å•†åœˆåˆ†ç´š (ç¸½è¨ˆ{len(circles)}å€‹å•†åœˆ) + è¡—é“åœ–', fontsize=14, fontweight='bold')\n",
    "ax4.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nåœ–ä¾‹èªªæ˜:\")\n",
    "print(f\"  é»‘é»: é¤é£²POIä½ç½® (å…±{len(catering_anlyzed)}ç­†)\")\n",
    "print(f\"  ç´…è‰²å€åŸŸ: Tier 1 æ ¸å¿ƒå•†åœˆ\")\n",
    "print(f\"  æ©˜è‰²å€åŸŸ: Tier 2 å€åŸŸå•†åœˆ\")\n",
    "print(f\"  ç¸½å•†åœˆæ•¸: {len(circles)}\")\n",
    "print(f\"  ç¸½Clusteræ•¸: {len(clusters)}\")\n",
    "if use_basemap:\n",
    "    print(f\"  åº•åœ–: OpenStreetMap è¡—é“åœ–\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c426408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HH æ ¸å¿ƒå€åŸŸæ¼¸å±¤åœ–ï¼ˆç¨ç«‹å¤§åœ–ï¼‰\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 16))\n",
    "\n",
    "# åº•å±¤ï¼šæ‰€æœ‰ç¶²æ ¼æ·¡è‰²èƒŒæ™¯\n",
    "grid_with_kde.plot(ax=ax, color='whitesmoke', edgecolor='white', linewidth=0.1, alpha=0.5)\n",
    "\n",
    "# æ ¸å¿ƒå±¤ï¼šHHæ ¼å­ä¾ Score_i é¡¯ç¤ºè—â†’ç¶ â†’é»ƒæ¼¸å±¤\n",
    "hh_grids = grid_with_kde[grid_with_kde['HH_flag']]\n",
    "\n",
    "if len(hh_grids) > 0:\n",
    "    # ä½¿ç”¨ YlGnBu_r è‰²éšï¼ˆåè½‰ï¼‰ï¼šæ·±è—(é«˜åˆ†) -> ç¶  -> é»ƒ(ä½åˆ†)\n",
    "    # æˆ–ä½¿ç”¨ viridis_rï¼šæ·±è—ç´«(é«˜åˆ†) -> ç¶  -> é»ƒ(ä½åˆ†)\n",
    "    hh_grids.plot(column='Score_i', cmap='viridis_r', ax=ax, \n",
    "                  edgecolor='none', linewidth=0, alpha=0.9,\n",
    "                  legend=True, \n",
    "                  legend_kwds={\n",
    "                      'label': 'HHæ ¸å¿ƒå€ é¤é£²ç«åŠ›æŒ‡æ•¸ (Score_i)', \n",
    "                      'shrink': 0.8,\n",
    "                      'orientation': 'horizontal',\n",
    "                      'pad': 0.05\n",
    "                  },\n",
    "                  vmin=hh_grids['Score_i'].quantile(0.1),  # æœ€å°å€¼ç”¨10åˆ†ä½\n",
    "                  vmax=hh_grids['Score_i'].max())           # æœ€å¤§å€¼\n",
    "    \n",
    "    print(f\"HHæ ¸å¿ƒå€çµ±è¨ˆ:\")\n",
    "    print(f\"  æ ¼å­æ•¸: {len(hh_grids)}\")\n",
    "    print(f\"  Score_i ç¯„åœ: {hh_grids['Score_i'].min():.1f} - {hh_grids['Score_i'].max():.1f}\")\n",
    "    print(f\"  Score_i å¹³å‡: {hh_grids['Score_i'].mean():.1f}\")\n",
    "    print(f\"  åˆ†ä½æ•¸:\")\n",
    "    print(f\"    Q25: {hh_grids['Score_i'].quantile(0.25):.1f}\")\n",
    "    print(f\"    Q50: {hh_grids['Score_i'].quantile(0.50):.1f}\")\n",
    "    print(f\"    Q75: {hh_grids['Score_i'].quantile(0.75):.1f}\")\n",
    "else:\n",
    "    print(\"è­¦å‘Šï¼šæ²’æœ‰HHæ ¸å¿ƒå€\")\n",
    "\n",
    "# ç¹ªè£½é¤é£²POIï¼ˆé»‘è‰²å°é»ï¼‰\n",
    "catering_anlyzed.plot(ax=ax, color='black', markersize=3, alpha=0.5, zorder=3)\n",
    "\n",
    "# æ·»åŠ è¡—é“åœ–åº•åœ–\n",
    "if use_basemap:\n",
    "    try:\n",
    "        cx.add_basemap(ax, crs=grid_with_kde.crs.to_string(), \n",
    "                       source=cx.providers.OpenStreetMap.Mapnik, \n",
    "                       alpha=0.6, zorder=1)\n",
    "    except Exception as e:\n",
    "        print(f\"åº•åœ–è¼‰å…¥å¤±æ•—: {e}\")\n",
    "\n",
    "# è¨­å®šæ¨™é¡Œå’Œæ¨£å¼\n",
    "ax.set_title('æ–°åŒ—å¸‚ä¸‰é‡å€ - HH é¤é£²å•†æ¥­æ ¸å¿ƒå€ç«åŠ›åœ–\\nï¼ˆæ·±è—=æœ€å¼· â†’ ç¶ =ä¸­ç­‰ â†’ é»ƒ=è¼ƒå¼±ï¼‰', \n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "ax.axis('off')\n",
    "\n",
    "# æ·»åŠ æ¯”ä¾‹å°º\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "scale_length = 500  # 500å…¬å°º\n",
    "ax.add_patch(Rectangle((0.02, 0.02), 0.1, 0.01, transform=ax.transAxes, \n",
    "                       facecolor='white', edgecolor='black', linewidth=2))\n",
    "ax.text(0.07, 0.04, f'{scale_length}m', transform=ax.transAxes, \n",
    "        ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor='black'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nåœ–ä¾‹èªªæ˜:\")\n",
    "print(f\"  ğŸ”µ æ·±è—è‰²: é¤é£²ç«åŠ›æœ€å¼·çš„æ ¸å¿ƒå€åŸŸï¼ˆScore_i > {hh_grids['Score_i'].quantile(0.75) if len(hh_grids) > 0 else 'N/A'}ï¼‰\")\n",
    "print(f\"  ğŸŸ¢ ç¶ è‰²: é¤é£²ç«åŠ›ä¸­ç­‰çš„æ ¸å¿ƒå€åŸŸ\")\n",
    "print(f\"  ğŸŸ¡ é»ƒè‰²: é¤é£²ç«åŠ›è¼ƒå¼±çš„æ ¸å¿ƒå€åŸŸ\")\n",
    "print(f\"  âš« é»‘é»: é¤é£²POIä½ç½® (å…±{len(catering_anlyzed)}ç­†)\")\n",
    "if use_basemap:\n",
    "    print(f\"  ğŸ—ºï¸ åº•åœ–: OpenStreetMap è¡—é“åœ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qthraet7a0e",
   "metadata": {},
   "source": [
    "## 7. æ•æ„Ÿåº¦åˆ†æ\n",
    "\n",
    "æ¸¬è©¦ä¸åŒåƒæ•¸çµ„åˆçš„ç©©å®šæ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cco72g0s2v8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_analysis(grid_raw_df, grid_geo_df, h=600, d0=900, alpha=1):\n",
    "    \"\"\"\n",
    "    åŸ·è¡Œå®Œæ•´åˆ†ææµç¨‹\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        grid_raw_df: åŒ…å«grid_idå’Œraw_içš„DataFrame\n",
    "        grid_geo_df: åŒ…å«å¹¾ä½•è³‡è¨Šçš„GeoDataFrame\n",
    "        h: KDEé »å¯¬\n",
    "        d0: LISAè·é›¢é–¾å€¼\n",
    "        alpha: è·é›¢è¡°æ¸›åƒæ•¸\n",
    "    \n",
    "    è¿”å›:\n",
    "        circles GeoDataFrame\n",
    "    \"\"\"\n",
    "    # åˆä½µè³‡æ–™\n",
    "    analysis_grid = grid_geo_df.merge(grid_raw_df, on='grid_id', how='left')\n",
    "    analysis_grid['raw_i'] = analysis_grid['raw_i'].fillna(0)\n",
    "    \n",
    "    # è¨ˆç®—ä¸­å¿ƒé»\n",
    "    analysis_grid['centroid'] = analysis_grid.geometry.centroid\n",
    "    analysis_grid['centroid_x'] = analysis_grid['centroid'].x\n",
    "    analysis_grid['centroid_y'] = analysis_grid['centroid'].y\n",
    "    \n",
    "    # KDE\n",
    "    analysis_grid = compute_kde_density(analysis_grid, bandwidth=h)\n",
    "    analysis_grid['rank_pct'] = analysis_grid['D_i'].rank(pct=True)\n",
    "    analysis_grid['Score_i'] = analysis_grid['rank_pct'] * 100\n",
    "    \n",
    "    # LISA\n",
    "    analysis_grid['z_i'] = zscore(analysis_grid['Score_i'])\n",
    "    w = create_distance_decay_weights(analysis_grid, threshold=d0, alpha=alpha)\n",
    "    lisa = Moran_Local(analysis_grid['z_i'].values, w, permutations=999)\n",
    "    \n",
    "    analysis_grid['I_i'] = lisa.Is\n",
    "    analysis_grid['p_value'] = lisa.p_sim\n",
    "    \n",
    "    # è¨ˆç®—ç©ºé–“æ»¯å¾Œå€¼\n",
    "    z_values = analysis_grid['z_i'].values\n",
    "    lag_z = np.zeros(len(z_values))\n",
    "    for i in range(len(z_values)):\n",
    "        if i in w.neighbors:\n",
    "            neighbors = w.neighbors[i]\n",
    "            weights = w.weights[i]\n",
    "            lag_z[i] = sum(weights[j] * z_values[neighbors[j]] for j in range(len(neighbors)))\n",
    "    analysis_grid['lag_z_i'] = lag_z\n",
    "    \n",
    "    quadrant_map = {1: 'HH', 2: 'LH', 3: 'LL', 4: 'HL', 0: 'Non-significant'}\n",
    "    analysis_grid['quadrant'] = [quadrant_map.get(q, 'Non-significant') for q in lisa.q]\n",
    "    \n",
    "    # FDRæ ¡æ­£\n",
    "    reject, q_values, _, _ = multipletests(analysis_grid['p_value'], method='fdr_bh')\n",
    "    analysis_grid['q_value'] = q_values\n",
    "    \n",
    "    # HHç¯©é¸\n",
    "    analysis_grid['HH_flag'] = (\n",
    "        (analysis_grid['quadrant'] == 'HH') &\n",
    "        (analysis_grid['z_i'] > 0) &\n",
    "        (analysis_grid['lag_z_i'] > 0) &\n",
    "        (analysis_grid['q_value'] < 0.05)\n",
    "    )\n",
    "    \n",
    "    # Clusters\n",
    "    hh_grids = analysis_grid[analysis_grid['HH_flag']].copy()\n",
    "    \n",
    "    if len(hh_grids) == 0:\n",
    "        return gpd.GeoDataFrame(columns=['cluster_id', 'tier', 'N_grids', 'TotalPower'], crs=analysis_grid.crs)\n",
    "    \n",
    "    clusters_dissolved = hh_grids.dissolve()\n",
    "    clusters_list = []\n",
    "    for idx, row in clusters_dissolved.iterrows():\n",
    "        geom = row.geometry\n",
    "        if geom.geom_type == 'MultiPolygon':\n",
    "            for poly in geom.geoms:\n",
    "                clusters_list.append({'geometry': poly})\n",
    "        else:\n",
    "            clusters_list.append({'geometry': geom})\n",
    "    \n",
    "    clusters = gpd.GeoDataFrame(clusters_list, crs=hh_grids.crs)\n",
    "    clusters['cluster_id'] = range(1, len(clusters) + 1)\n",
    "    \n",
    "    # çµ±è¨ˆ\n",
    "    hh_with_cluster = gpd.sjoin(hh_grids, clusters[['cluster_id', 'geometry']], how='left', predicate='within')\n",
    "    cluster_stats = hh_with_cluster.groupby('cluster_id').agg({\n",
    "        'grid_id': 'count',\n",
    "        'Score_i': ['sum', 'max'],\n",
    "    }).reset_index()\n",
    "    cluster_stats.columns = ['cluster_id', 'N_grids', 'TotalPower', 'Peak']\n",
    "    \n",
    "    clusters = clusters.merge(cluster_stats, on='cluster_id', how='left')\n",
    "    \n",
    "    # åˆ†ç´š\n",
    "    if len(clusters) > 0:\n",
    "        p90_totalpower = clusters['TotalPower'].quantile(0.9)\n",
    "        mean_totalpower = clusters['TotalPower'].mean()\n",
    "        \n",
    "        def classify_tier(row):\n",
    "            if row['N_grids'] >= 10 and row['TotalPower'] >= p90_totalpower:\n",
    "                return 'Tier 1'\n",
    "            elif row['N_grids'] >= 4 and row['TotalPower'] >= mean_totalpower:\n",
    "                return 'Tier 2'\n",
    "            else:\n",
    "                return 'Non-Circle'\n",
    "        \n",
    "        clusters['tier'] = clusters.apply(classify_tier, axis=1)\n",
    "        circles = clusters[clusters['tier'] != 'Non-Circle'].copy()\n",
    "    else:\n",
    "        circles = gpd.GeoDataFrame(columns=['cluster_id', 'tier', 'N_grids', 'TotalPower'], crs=analysis_grid.crs)\n",
    "    \n",
    "    return circles\n",
    "\n",
    "print(\"æ•æ„Ÿåº¦åˆ†æå‡½æ•¸å®šç¾©å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jd1pydn4nci",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šç¾©åƒæ•¸çµ„åˆ\n",
    "param_combinations = [\n",
    "    {'h': 450, 'd0': 600, 'alpha': 1},\n",
    "    {'h': 450, 'd0': 900, 'alpha': 1},\n",
    "    {'h': 450, 'd0': 1200, 'alpha': 1},\n",
    "    {'h': 450, 'd0': 900, 'alpha': 2},\n",
    "    {'h': 600, 'd0': 600, 'alpha': 1},\n",
    "    {'h': 600, 'd0': 900, 'alpha': 1},  # é è¨­çµ„åˆ\n",
    "    {'h': 600, 'd0': 1200, 'alpha': 1},\n",
    "    {'h': 600, 'd0': 900, 'alpha': 2},\n",
    "]\n",
    "\n",
    "# åŸ·è¡Œæ•æ„Ÿåº¦åˆ†æ\n",
    "sensitivity_results = []\n",
    "\n",
    "print(\"é–‹å§‹æ•æ„Ÿåº¦åˆ†æ...\")\n",
    "for i, params in enumerate(param_combinations):\n",
    "    print(f\"\\n[{i+1}/{len(param_combinations)}] h={params['h']}, d0={params['d0']}, alpha={params['alpha']}\")\n",
    "    \n",
    "    circles_result = run_full_analysis(\n",
    "        grid_raw_df=grid_raw[['grid_id', 'raw_i']],\n",
    "        grid_geo_df=grid_sanzhong[['grid_id', 'geometry', 'TOWNNAME']],\n",
    "        h=params['h'],\n",
    "        d0=params['d0'],\n",
    "        alpha=params['alpha']\n",
    "    )\n",
    "    \n",
    "    # è¨˜éŒ„çµæœ\n",
    "    result = {\n",
    "        'h': params['h'],\n",
    "        'd0': params['d0'],\n",
    "        'alpha': params['alpha'],\n",
    "        'n_circles': len(circles_result),\n",
    "        'n_tier1': len(circles_result[circles_result['tier'] == 'Tier 1']) if len(circles_result) > 0 else 0,\n",
    "        'n_tier2': len(circles_result[circles_result['tier'] == 'Tier 2']) if len(circles_result) > 0 else 0,\n",
    "        'avg_n_grids': circles_result['N_grids'].mean() if len(circles_result) > 0 else 0,\n",
    "        'avg_totalpower': circles_result['TotalPower'].mean() if len(circles_result) > 0 else 0,\n",
    "    }\n",
    "    sensitivity_results.append(result)\n",
    "    \n",
    "    print(f\"  å•†åœˆæ•¸: {result['n_circles']}, Tier1: {result['n_tier1']}, Tier2: {result['n_tier2']}\")\n",
    "\n",
    "# å»ºç«‹å ±è¡¨\n",
    "sensitivity_df = pd.DataFrame(sensitivity_results)\n",
    "print(\"\\n=== æ•æ„Ÿåº¦åˆ†æå ±è¡¨ ===\")\n",
    "print(sensitivity_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd97bn5eqw",
   "metadata": {},
   "source": [
    "## 8. å„²å­˜çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nt3b6bi94ze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å„²å­˜ä¸»è¦çµæœ\n",
    "output_dir = Path(r\"C:\\labs\\geo-grid\\data\\output_analysis\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1. å„²å­˜gridåˆ†æçµæœ\n",
    "grid_analysis_path = output_dir / \"grid_sanzhong_analysis.parquet\"\n",
    "grid_with_kde.to_parquet(grid_analysis_path)\n",
    "print(f\"ç¶²æ ¼åˆ†æçµæœå·²å„²å­˜: {grid_analysis_path}\")\n",
    "\n",
    "# 2. å„²å­˜clusters\n",
    "if len(clusters) > 0:\n",
    "    clusters_path = output_dir / \"clusters_sanzhong.parquet\"\n",
    "    clusters.to_parquet(clusters_path)\n",
    "    print(f\"Clusterså·²å„²å­˜: {clusters_path}\")\n",
    "\n",
    "# 3. å„²å­˜circles\n",
    "if len(circles) > 0:\n",
    "    circles_path = output_dir / \"circles_sanzhong.parquet\"\n",
    "    circles.to_parquet(circles_path)\n",
    "    print(f\"å•†åœˆçµæœå·²å„²å­˜: {circles_path}\")\n",
    "\n",
    "# 4. å„²å­˜æ•æ„Ÿåº¦åˆ†æå ±è¡¨\n",
    "sensitivity_path = output_dir / \"sensitivity_report.csv\"\n",
    "sensitivity_df.to_csv(sensitivity_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"æ•æ„Ÿåº¦åˆ†æå ±è¡¨å·²å„²å­˜: {sensitivity_path}\")\n",
    "\n",
    "print(\"\\næ‰€æœ‰çµæœå·²å„²å­˜å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sfel8ckwr3",
   "metadata": {},
   "source": [
    "## ç¸½çµ\n",
    "\n",
    "æœ¬åˆ†ææµç¨‹å®Œæˆäº†ä»¥ä¸‹æ­¥é©Ÿï¼š\n",
    "\n",
    "1. **POIç‰¹å¾µå·¥ç¨‹**: å°‡é¤é£²POIåˆ†é¡ç‚ºç›®çš„å‹/è£œçµ¦å‹ï¼Œè¨­å®šæ¬Šé‡èˆ‡capå€¼ï¼Œè¨ˆç®—æ¯æ ¼çš„raw_iåˆ†æ•¸\n",
    "2. **ç©ºé–“å°ä½**: å°‡POIèˆ‡100mç¶²æ ¼é€²è¡Œç©ºé–“joinï¼Œçµ±è¨ˆæ¯æ ¼çš„é¤é£²æ¥­æ…‹åˆ†å¸ƒ\n",
    "3. **KDEå¯†åº¦ä¼°è¨ˆ**: ä½¿ç”¨ç¶²æ ¼ä¸­å¿ƒé»å’Œraw_iæ¬Šé‡è¨ˆç®—å¹³æ»‘çš„é¤é£²ç«åŠ›å¯†åº¦å ´ï¼Œè½‰æ›ç‚º0-100åˆ†çš„Score_i\n",
    "4. **LISAåˆ†æ**: å»ºç«‹è·é›¢è¡°æ¸›æ¬Šé‡çŸ©é™£ï¼Œè¨ˆç®—Local Moran's Iï¼Œè­˜åˆ¥HH (High-High)èšé›†å€\n",
    "5. **å¤šé‡æ¯”è¼ƒæ ¡æ­£**: ä½¿ç”¨BH-FDRæ–¹æ³•æ ¡æ­£p-valueï¼Œé™ä½å‡é™½æ€§ç‡\n",
    "6. **å•†æ¥­å€ç”Ÿæˆ**: å°‡HHæ ¼å­dissolveæˆé€£çºŒçš„clustersï¼Œè¨ˆç®—è¦æ¨¡èˆ‡ç«åŠ›å±¬æ€§\n",
    "7. **å•†åœˆåˆ†ç´š**: æ ¹æ“šç¶²æ ¼æ•¸èˆ‡ç¸½ç«åŠ›å°‡clustersåˆ†ç‚ºTier 1 (æ ¸å¿ƒå•†åœˆ) å’Œ Tier 2 (å€åŸŸå•†åœˆ)\n",
    "8. **æ•æ„Ÿåº¦åˆ†æ**: æ¸¬è©¦ä¸åŒKDEé »å¯¬(h)ã€LISAè·é›¢é–¾å€¼(d0)ã€è·é›¢è¡°æ¸›åƒæ•¸(alpha)å°çµæœçš„å½±éŸ¿\n",
    "\n",
    "### ä¸»è¦ç™¼ç¾ (ä»¥ä¸‰é‡å€ç‚ºä¾‹)\n",
    "- HHæ ¼å­æ•¸é‡: [åŸ·è¡Œå¾Œé¡¯ç¤º]\n",
    "- å•†åœˆç¸½æ•¸: [åŸ·è¡Œå¾Œé¡¯ç¤º]\n",
    "- Tier 1 å•†åœˆ: [åŸ·è¡Œå¾Œé¡¯ç¤º]\n",
    "- Tier 2 å•†åœˆ: [åŸ·è¡Œå¾Œé¡¯ç¤º]\n",
    "\n",
    "### åƒæ•¸å»ºè­°\n",
    "- KDEé »å¯¬: 600m (å¯è¦–æƒ…æ³èª¿æ•´è‡³450m)\n",
    "- LISAè·é›¢é–¾å€¼: 900m\n",
    "- è·é›¢è¡°æ¸›: alpha=1 (ç·šæ€§è¡°æ¸›)\n",
    "\n",
    "### å¾ŒçºŒå¯å»¶ä¼¸æ–¹å‘\n",
    "1. æ“´å±•è‡³å…¶ä»–è¡Œæ”¿å€é€²è¡Œæ¯”è¼ƒåˆ†æ\n",
    "2. çµåˆå…¶ä»–POIé¡åˆ¥ï¼ˆé›¶å”®ã€å¨›æ¨‚ç­‰ï¼‰é€²è¡Œå¤šç¶­åº¦åˆ†æ\n",
    "3. æ™‚é–“åºåˆ—åˆ†æï¼ˆæ¯”è¼ƒä¸åŒæ™‚æœŸçš„å•†åœˆè®ŠåŒ–ï¼‰\n",
    "4. èˆ‡å¯¦éš›å•†åœˆè³‡æ–™é€²è¡Œé©—è­‰èˆ‡æ ¡æº–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab381daa",
   "metadata": {},
   "source": [
    "### 6.4 å¤šå•†æ¥­å€æ¼¸å±¤åœ–ï¼ˆé¡¯ç¤ºæ‰€æœ‰ Clustersï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b88e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¤šå•†æ¥­å€æ¼¸å±¤åœ–ï¼ˆç¨ç«‹å¤§åœ–ï¼‰\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 16))\n",
    "\n",
    "# åº•å±¤ï¼šæ‰€æœ‰ç¶²æ ¼æ·¡è‰²èƒŒæ™¯\n",
    "grid_with_kde.plot(ax=ax, color='whitesmoke', edgecolor='white', linewidth=0.1, alpha=0.5)\n",
    "\n",
    "# æ ¸å¿ƒå±¤ï¼šHHæ ¼å­ä¾ Score_i é¡¯ç¤ºè—â†’ç¶ â†’é»ƒæ¼¸å±¤\n",
    "hh_grids = grid_with_kde[grid_with_kde['HH_flag']]\n",
    "\n",
    "if len(hh_grids) > 0:\n",
    "    # ä½¿ç”¨ viridis_r è‰²éšï¼šæ·±è—(é«˜åˆ†) -> ç¶  -> é»ƒ(ä½åˆ†)\n",
    "    hh_grids.plot(column='Score_i', cmap='viridis_r', ax=ax, \n",
    "                  edgecolor='black', linewidth=0.5, alpha=0.9,\n",
    "                  legend=True, \n",
    "                  legend_kwds={\n",
    "                      'label': 'HHæ ¸å¿ƒå€ é¤é£²ç«åŠ›æŒ‡æ•¸ (Score_i)', \n",
    "                      'shrink': 0.8,\n",
    "                      'orientation': 'horizontal',\n",
    "                      'pad': 0.05\n",
    "                  },\n",
    "                  vmin=hh_grids['Score_i'].quantile(0.1),\n",
    "                  vmax=hh_grids['Score_i'].max())\n",
    "    \n",
    "    print(f\"HHæ ¸å¿ƒå€çµ±è¨ˆ:\")\n",
    "    print(f\"  ç¸½æ ¼å­æ•¸: {len(hh_grids)}\")\n",
    "    print(f\"  Clustersæ•¸: {len(clusters)}\")\n",
    "    print(f\"  Score_i ç¯„åœ: {hh_grids['Score_i'].min():.1f} - {hh_grids['Score_i'].max():.1f}\")\n",
    "    \n",
    "    # é¡¯ç¤ºæ¯å€‹clusterçš„çµ±è¨ˆ\n",
    "    if len(clusters) > 0:\n",
    "        print(f\"\\nå„ Cluster è³‡è¨Š:\")\n",
    "        for idx, row in clusters.iterrows():\n",
    "            print(f\"  Cluster {row['cluster_id']}: {row['n_grids_in_cluster']}æ ¼\")\n",
    "else:\n",
    "    print(\"è­¦å‘Šï¼šæ²’æœ‰HHæ ¸å¿ƒå€\")\n",
    "\n",
    "# ç¹ªè£½clusteré‚Šç•Œï¼ˆä¸åŒé¡è‰²ï¼‰\n",
    "if len(clusters) > 1:\n",
    "    colors = ['blue', 'cyan', 'green', 'magenta', 'orange']\n",
    "    for idx, row in clusters.iterrows():\n",
    "        color = colors[idx % len(colors)]\n",
    "        gpd.GeoSeries([row.geometry], crs=clusters.crs).boundary.plot(\n",
    "            ax=ax, color=color, linewidth=3, linestyle='--', \n",
    "            label=f'Cluster {row[\"cluster_id\"]}', zorder=5)\n",
    "\n",
    "# ç¹ªè£½é¤é£²POIï¼ˆé»‘è‰²å°é»ï¼‰\n",
    "catering_anlyzed.plot(ax=ax, color='black', markersize=2, alpha=0.4, zorder=3)\n",
    "\n",
    "# æ·»åŠ è¡—é“åœ–åº•åœ–\n",
    "if use_basemap:\n",
    "    try:\n",
    "        cx.add_basemap(ax, crs=grid_with_kde.crs.to_string(), \n",
    "                       source=cx.providers.OpenStreetMap.Mapnik, \n",
    "                       alpha=0.6, zorder=1)\n",
    "    except Exception as e:\n",
    "        print(f\"åº•åœ–è¼‰å…¥å¤±æ•—: {e}\")\n",
    "\n",
    "# è¨­å®šæ¨™é¡Œå’Œæ¨£å¼\n",
    "ax.set_title(f'æ–°åŒ—å¸‚ä¸‰é‡å€ - é¤é£²å•†æ¥­å€åˆ†å¸ƒåœ– ({len(clusters)} å€‹ç¨ç«‹å•†æ¥­å€)\\nï¼ˆæ·±è—=æœ€å¼· â†’ ç¶ =ä¸­ç­‰ â†’ é»ƒ=è¼ƒå¼±ï¼‰', \n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "if len(clusters) > 1:\n",
    "    ax.legend(loc='upper right', fontsize=12, framealpha=0.9)\n",
    "ax.axis('off')\n",
    "\n",
    "# æ·»åŠ æ¯”ä¾‹å°º\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "scale_length = 500  # 500å…¬å°º\n",
    "ax.add_patch(Rectangle((0.02, 0.02), 0.1, 0.01, transform=ax.transAxes, \n",
    "                       facecolor='white', edgecolor='black', linewidth=2))\n",
    "ax.text(0.07, 0.04, f'{scale_length}m', transform=ax.transAxes, \n",
    "        ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor='black'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nåœ–ä¾‹èªªæ˜:\")\n",
    "print(f\"  ğŸ”µ æ·±è—è‰²: é¤é£²ç«åŠ›æœ€å¼·\")\n",
    "print(f\"  ğŸŸ¢ ç¶ è‰²: é¤é£²ç«åŠ›ä¸­ç­‰\")\n",
    "print(f\"  ğŸŸ¡ é»ƒè‰²: é¤é£²ç«åŠ›è¼ƒå¼±\")\n",
    "print(f\"  â¬› é»‘è‰²é‚Šç·š: 100m Ã— 100m ç¶²æ ¼\")\n",
    "print(f\"  âš« é»‘é»: é¤é£²POIä½ç½® (å…±{len(catering_anlyzed)}ç­†)\")\n",
    "print(f\"  ğŸ”· è™›ç·šé‚Šç•Œ: å„ç¨ç«‹å•†æ¥­å€é‚Šç•Œ (å…±{len(clusters)}å€‹)\")\n",
    "if use_basemap:\n",
    "    print(f\"  ğŸ—ºï¸ åº•åœ–: OpenStreetMap è¡—é“åœ–\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo-grid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
